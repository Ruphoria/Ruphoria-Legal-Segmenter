{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4890b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T13:57:23.914010Z",
     "start_time": "2023-03-03T13:57:21.621211Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import argparse\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.functional as tF\n",
    "import pytorch_lightning as pl\n",
    "import tokenizers\n",
    "import datasets\n",
    "\n",
    "\n",
    "DEBUG_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e7dfc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T13:57:23.918031Z",
     "start_time": "2023-03-03T13:57:23.915293Z"
    }
   },
   "outputs": [],
   "source": [
    "class HFDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hfdf):\n",
    "        self.hfdf = hfdf\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.hfdf[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hfdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cae9a71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T15:56:43.660235Z",
     "start_time": "2023-03-03T15:56:43.639417Z"
    }
   },
   "outputs": [],
   "source": [
    "class LitSegmenterBaseline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int,\n",
    "        tokenizer_uri: str,\n",
    "        dataset_uri: str,\n",
    "        batch_size: int,\n",
    "        num_layers: int = 1,\n",
    "        bidirectional: bool = True,\n",
    "        num_classes: int = 4,\n",
    "        pad_token: str = \"[PAD]\",\n",
    "    ):\n",
    "        super(LitSegmenterBaseline, self).__init__()\n",
    "\n",
    "        self.tokenizer = tokenizers.Tokenizer.from_file(tokenizer_uri)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.pad_id = self.tokenizer.get_vocab().get(pad_token, 0)\n",
    "\n",
    "        def fn_pad_sequences(batch):\n",
    "            X = [torch.tensor(x_i[\"input_ids\"], dtype=torch.int) for x_i in batch]\n",
    "            y = [torch.tensor(y_i[\"labels\"]) for y_i in batch]\n",
    "\n",
    "            X = nn.utils.rnn.pad_sequence(X, padding_value=self.pad_id, batch_first=True)\n",
    "            y = nn.utils.rnn.pad_sequence(y, padding_value=-100, batch_first=True)\n",
    "\n",
    "            return X, y\n",
    "\n",
    "        self.fn_pad_sequences = fn_pad_sequences\n",
    "\n",
    "        if isinstance(dataset_uri, str):\n",
    "            self.hfdf = datasets.load_from_disk(dataset_uri)\n",
    "            \n",
    "        else:\n",
    "            dfs = []\n",
    "            for uri in dataset_uri:\n",
    "                dfs.append(datasets.load_from_disk(uri))\n",
    "            \n",
    "            hfdf = {}\n",
    "            for key in dfs[0].keys():\n",
    "                hfdf[key] = datasets.concatenate_datasets([df[key] for df in dfs])\n",
    "            \n",
    "            self.hfdf = datasets.DatasetDict(hfdf)\n",
    "\n",
    "        print(self.hfdf)\n",
    "            \n",
    "        self.embeddings = nn.Embedding(\n",
    "            num_embeddings=self.tokenizer.get_vocab_size(),\n",
    "            embedding_dim=768,\n",
    "            padding_idx=self.pad_id,\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=768,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.0 if num_layers == 1 else 0.1,\n",
    "            bidirectional=bidirectional,\n",
    "            proj_size=0,\n",
    "        )\n",
    "\n",
    "        self.lin_out = nn.Linear(\n",
    "            (1 + int(bidirectional)) * hidden_size,\n",
    "            num_classes,\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = X\n",
    "\n",
    "        if isinstance(out, str):\n",
    "            out = self.tokenizer(out, return_tensors=\"pt\")\n",
    "            out = out[\"input_ids\"]\n",
    "\n",
    "        out = self.embeddings(out)\n",
    "        out, *_ = self.lstm(out)\n",
    "        out = self.lin_out(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_pred_metrics(y_preds, y, phase: str) -> dict[str, float]:\n",
    "        y_preds = y_preds.view(-1, y_preds.shape[-1])\n",
    "        y = y.view(-1).squeeze()\n",
    "\n",
    "        loss = F.cross_entropy(input=y_preds, target=y, ignore_index=-100)\n",
    "\n",
    "        non_pad_inds = [i for i, cls_i in enumerate(y) if cls_i != -100]\n",
    "\n",
    "        per_cls_recall = tF.recall(\n",
    "            preds=y_preds[non_pad_inds, ...],\n",
    "            target=y[non_pad_inds],\n",
    "            num_classes=4,\n",
    "            average=None,\n",
    "        )\n",
    "\n",
    "        per_cls_precision = tF.precision(\n",
    "            preds=y_preds[non_pad_inds, ...],\n",
    "            target=y[non_pad_inds],\n",
    "            num_classes=4,\n",
    "            average=None,\n",
    "        )\n",
    "\n",
    "        macro_precision = float(per_cls_precision.mean().item())\n",
    "        macro_recall = float(per_cls_recall.mean().item())\n",
    "        macro_f1_score = (\n",
    "            2.0 * macro_precision * macro_recall / (1e-8 + macro_precision + macro_recall)\n",
    "        )\n",
    "\n",
    "        out = {\n",
    "            f\"{(phase + '_') if phase != 'train' else ''}loss\": loss,\n",
    "            **{f\"{phase}_cls_{i}_precision\": float(val) for i, val in enumerate(per_cls_precision)},\n",
    "            **{f\"{phase}_cls_{i}_recall\": float(val) for i, val in enumerate(per_cls_recall)},\n",
    "            f\"{phase}_macro_precision\": macro_precision,\n",
    "            f\"{phase}_macro_recall\": macro_recall,\n",
    "            f\"{phase}_macro_f1_score\": macro_f1_score,\n",
    "        }\n",
    "\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def _agg_stats(step_outputs):\n",
    "        out = {}\n",
    "        agg_items = collections.defaultdict(list)\n",
    "\n",
    "        for items in step_outputs:\n",
    "            for key, val in items.items():\n",
    "                if not isinstance(val, torch.Tensor):\n",
    "                    val = torch.tensor(val)\n",
    "\n",
    "                agg_items[key].append(val)\n",
    "\n",
    "        for key, vals in agg_items.items():\n",
    "            avg_vals = float(torch.stack(vals).mean().item())\n",
    "            out[f\"avg_{key}\"] = avg_vals\n",
    "\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx: int):\n",
    "        X, y = batch\n",
    "        y_preds = self.forward(X)\n",
    "\n",
    "        out = self._compute_pred_metrics(y_preds, y, phase=\"train\")\n",
    "\n",
    "        self.log_dict(\n",
    "            out,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "        return out\n",
    "\n",
    "    def tr